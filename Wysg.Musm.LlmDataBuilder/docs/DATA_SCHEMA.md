# Data Schema Documentation

## Overview

The LLM Data Builder uses a simple JSON schema to store training data records. This document provides detailed information about the data structure.

## JSON File: data.json

### Location
- Stored in the application's base directory
- Typically: `bin\Debug\net9.0-windows\data.json` or `bin\Release\net9.0-windows\data.json`

### Structure

The file contains a JSON array of `LlmDataRecord` objects:

```json
[
  {
    "input": "string",
    "output": "string",
    "protoOutput": "string",
    "appliedPromptNumbers": [1, 2, 3]
  }
]
```

## LlmDataRecord Object

### Field Definitions

#### input
- **Type**: `string`
- **Required**: Yes (validated at save time)
- **Description**: The input prompt, question, or instruction to be given to the LLM
- **Usage**: This is what you want the model to respond to
- **Examples**:
  ```json
  "input": "What is the capital of France?"
  "input": "Translate the following to Spanish: Hello, how are you?"
  "input": "Summarize this article: [article text]"
  ```

#### output
- **Type**: `string`
- **Required**: Yes (validated at save time)
- **Description**: The expected or desired response from the LLM
- **Usage**: This is the "ground truth" or target output for training
- **Examples**:
  ```json
  "output": "The capital of France is Paris."
  "output": "Hola, ¢¯c?mo est?s?"
  "output": "The article discusses climate change impacts..."
  ```

#### protoOutput
- **Type**: `string`
- **Required**: No
- **Description**: A prototype or sample output generated by the LLM (for comparison or evaluation)
- **Usage**: Currently a placeholder; will be populated by the "Get Proto Result" feature in future versions
- **Default**: Empty string `""`
- **Examples**:
  ```json
  "protoOutput": "Paris is the capital and largest city of France."
  "protoOutput": ""
  ```

#### appliedPromptNumbers
- **Type**: `array of integers`
- **Required**: No
- **Description**: A list of prompt template IDs or numbers that were used/applied when creating this record
- **Usage**: Helps track which prompt engineering techniques or templates were used
- **Format**: Comma-separated integers in UI, stored as JSON array
- **Default**: Empty array `[]`
- **Examples**:
  ```json
  "appliedPromptNumbers": [1, 2, 3]
  "appliedPromptNumbers": [5]
  "appliedPromptNumbers": []
  ```

## Complete Example

### Single Record
```json
[
  {
    "input": "What are the three laws of robotics?",
    "output": "The Three Laws of Robotics are:\n1. A robot may not injure a human being or allow a human to come to harm.\n2. A robot must obey orders given by humans except where such orders would conflict with the First Law.\n3. A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.",
    "protoOutput": "",
    "appliedPromptNumbers": [1, 4, 7]
  }
]
```

### Multiple Records
```json
[
  {
    "input": "What is 2 + 2?",
    "output": "4",
    "protoOutput": "The answer is 4.",
    "appliedPromptNumbers": [1]
  },
  {
    "input": "Explain photosynthesis briefly.",
    "output": "Photosynthesis is the process by which plants use sunlight, water, and carbon dioxide to create oxygen and energy in the form of sugar.",
    "protoOutput": "",
    "appliedPromptNumbers": [2, 3]
  },
  {
    "input": "Translate to French: Good morning",
    "output": "Bonjour",
    "protoOutput": "Bonjour",
    "appliedPromptNumbers": []
  }
]
```

## C# Data Model

### Class Definition

```csharp
public class LlmDataRecord
{
    public string Input { get; set; } = string.Empty;
    public string Output { get; set; } = string.Empty;
    public string ProtoOutput { get; set; } = string.Empty;
    public List<int> AppliedPromptNumbers { get; set; } = new List<int>();
}
```

### Serialization Settings

The application uses `System.Text.Json` with the following options:

```csharp
var options = new JsonSerializerOptions
{
    WriteIndented = true,              // Pretty-print JSON
    PropertyNamingPolicy = JsonNamingPolicy.CamelCase  // Use camelCase for property names
};
```

This results in:
- Property names in camelCase (e.g., `appliedPromptNumbers`)
- Indented, readable JSON format
- Proper UTF-8 encoding

## Text File: prompt.txt

### Location
- Same directory as `data.json`

### Structure
- Plain text file
- No specific format requirements
- Contains the master prompt template

### Example
```
You are a helpful AI assistant. Please provide accurate and concise answers.

Context: {context}
Question: {question}

Answer:
```

## File Operations

### Append Behavior
- New records are **appended** to the existing array in `data.json`
- Existing records are **never modified or deleted** by the Save operation
- The entire array is read, a new record is added, and the complete array is written back

### File Creation
- If `data.json` doesn't exist, it will be created with the first record
- If `prompt.txt` doesn't exist, it will be created when first saved
- Both files are created in the application's base directory

## Data Validation

### Required Fields Validation
- **Input**: Must not be null, empty, or whitespace
- **Output**: Must not be null, empty, or whitespace

### Applied Prompt Numbers Validation
- Must be valid integers
- Must be comma-separated in the UI
- Can be empty (results in empty array)
- Invalid formats will show an error message

### Example Valid Inputs
```
Applied Prompt Numbers Field:
? "1,2,3"
? "5"
? "10, 20, 30"  (spaces are trimmed)
? ""  (empty is valid)

? "1,2,abc"  (contains non-integer)
? "1.5,2.3"  (contains decimals)
```

## Best Practices

### Data Entry
1. **Be consistent** with input/output formats
2. **Use descriptive inputs** that clearly state the task
3. **Provide complete outputs** that fully answer the input
4. **Track your prompts** using `appliedPromptNumbers` for reproducibility

### Prompt Management
1. **Version your prompts** - Consider adding version info in the prompt text
2. **Use placeholders** - Like `{context}`, `{question}` for template variables
3. **Document changes** - Keep notes about what prompt numbers mean

### File Management
1. **Backup regularly** - Copy `data.json` and `prompt.txt` to safe locations
2. **Use version control** - Consider tracking these files in Git
3. **Validate JSON** - Periodically check that `data.json` is valid JSON

## Integration Notes

### For Developers

When integrating this data with LLM training pipelines:

1. **Parse JSON**: Use any JSON library to read `data.json`
2. **Iterate records**: Process each record in the array
3. **Map fields**: 
   - `input` ¡æ model input/prompt
   - `output` ¡æ target/expected output
   - `protoOutput` ¡æ optional comparison baseline
   - `appliedPromptNumbers` ¡æ metadata for tracking

### Example Python Integration
```python
import json

# Load data
with open('data.json', 'r', encoding='utf-8') as f:
    records = json.load(f)

# Load prompt template
with open('prompt.txt', 'r', encoding='utf-8') as f:
    prompt_template = f.read()

# Process records
for record in records:
    input_text = record['input']
    expected_output = record['output']
    # Use for training...
```

## Schema Version

**Current Version**: 1.0

Future versions may add additional fields. The schema is designed to be backward compatible.

## Related Documents

- [README.md](README.md) - Full application documentation
- [QUICKSTART.md](QUICKSTART.md) - Quick start guide
- [API_INTEGRATION.md](API_INTEGRATION.md) - LLM server integration guide (when implemented)
